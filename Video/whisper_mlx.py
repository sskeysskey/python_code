import os
import pathlib
import subprocess
import logging
import re
# from zipfile import ZipFile
from typing import List, Dict, Any
# import json

import numpy as np
import mlx.core as mx
import mlx_whisper

import tkinter as tk
from tkinter import filedialog

# ============ é…ç½® logging =============
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)-8s %(message)s",
    datefmt="%H:%M:%S"
)

# ============ å¸¸é‡ =============
FFMPEG_BIN = "/opt/homebrew/bin/ffmpeg"

DEVICE = "mps" if mx.metal.is_available() else "cpu"
MODELS = {
    "tiny-q4":    "mlx-community/whisper-tiny-mlx-q4",
    "large-v3":   "mlx-community/whisper-large-v3-mlx",
    "small-q4":   "mlx-community/whisper-small.en-mlx-q4",
    "small-fp32": "mlx-community/whisper-small-mlx-fp32",
}
LANGUAGES = {
    "auto": None,
    "en": "English",
    "zh": "Chinese",
    "es": "Spanish",
}

BASE_DIR    = pathlib.Path("/Users/yanzhang/Downloads")
OUTPUT_DIR  = BASE_DIR
TEMP_DIR   = pathlib.Path("/tmp")

# /tmp ä¸€èˆ¬è‡ªå¸¦ï¼Œæ— éœ€ mkdir

# éŸ³é¢‘é¢„å¤„ç†å‚æ•°
AUDIO_PARAMS = {
    "sample_rate": 16000,
    "normalize_volume": True,
    "remove_noise": True,
    "voice_enhance": True
}

# Whisperæ¨¡å‹å‚æ•°
WHISPER_PARAMS = {
    "temperature": 0.0,  # 0è¡¨ç¤ºä½¿ç”¨è´ªå©ªè§£ç 
    "condition_on_previous_text": True,
    "word_timestamps": True,
    "prepend_punctuations": "\"'([{-",
    "append_punctuations": "\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼š)]}"
}

def enhance_audio(audio_path: str) -> str:
    """éŸ³é¢‘å¢å¼ºå¤„ç†"""
    temp_path = TEMP_DIR / f"enhanced_{os.path.basename(audio_path)}"
    
    cmd = [
        FFMPEG_BIN, "-y",
        "-i", audio_path,
        # é™å™ª
        "-af", "afftdn=nf=-25",
        # åŠ¨æ€èŒƒå›´å‹ç¼©
        "-af", "acompressor=threshold=-12dB:ratio=2:attack=200:release=1000",
        # éŸ³é‡å½’ä¸€åŒ–
        "-filter:a", "loudnorm=I=-16:LRA=11:TP=-1.5",
        str(temp_path)
    ]
    
    subprocess.run(cmd, check=True, stderr=subprocess.PIPE)
    return str(temp_path)

def prepare_audio(audio_path: str) -> mx.array:
    """ç”¨ ffmpeg è§£å‡º 16k å•å£°é“åŸå§‹ PCM å¹¶è½¬æˆ float32"""
    if AUDIO_PARAMS["voice_enhance"]:
        audio_path = enhance_audio(audio_path)
    
    cmd = [
        FFMPEG_BIN, "-y", "-i", audio_path,
        "-f", "s16le", "-acodec", "pcm_s16le",
        "-ar", str(AUDIO_PARAMS["sample_rate"]),
        "-ac", "1"
    ]
    
    if AUDIO_PARAMS["normalize_volume"]:
        cmd.extend(["-filter:a", "volume=2.0"])
    
    cmd.append("-")
    
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    raw, _ = p.communicate()
    
    # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–
    arr = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
    
    # å¦‚æœéœ€è¦é™å™ª
    if AUDIO_PARAMS["remove_noise"]:
        from scipy import signal
        # ç®€å•çš„é«˜é€šæ»¤æ³¢å»é™¤ä½é¢‘å™ªå£°
        b, a = signal.butter(4, 100/(AUDIO_PARAMS["sample_rate"]/2), 'high')
        arr = signal.filtfilt(b, a, arr)
    
    return mx.array(arr)

def post_process_text(text: str) -> str:
    """æ–‡æœ¬åå¤„ç†"""
    # ä¿®å¤æ•°å­—å’Œå•ä½ä¹‹é—´çš„ç©ºæ ¼
    text = re.sub(r'(\d+)\s+([a-zA-Z])', r'\1\2', text)
    
    # ä¿®å¤é‡å¤çš„æ ‡ç‚¹ç¬¦å·
    text = re.sub(r'([ã€‚ï¼Œï¼ï¼Ÿ!?])\1+', r'\1', text)
    
    # ä¿®å¤é”™è¯¯çš„çœç•¥å·
    text = re.sub(r'\.{2,}', '...', text)
    
    return text.strip()

def process_audio(model_repo: str, audio: mx.array, language: str = None) -> Dict[str, Any]:
    opts = {"language": language} if language else {}
    opts.update(WHISPER_PARAMS)
    
    logging.info(f"â†’ è°ƒç”¨ Whisper: model={model_repo}  language={language or 'auto'}")
    
    result = mlx_whisper.transcribe(
        audio,
        path_or_hf_repo=model_repo,
        fp16=False,
        verbose=True,
        **opts
    )
    
    # å¯¹æ¯ä¸ªsegmentè¿›è¡Œåå¤„ç†
    for segment in result["segments"]:
        segment["text"] = post_process_text(segment["text"])
        
        # ä¼˜åŒ–æ—¶é—´æˆ³
        if "words" in segment:
            for word in segment["words"]:
                # ç¡®ä¿å•è¯æ—¶é•¿åˆç†
                min_word_duration = len(word["word"]) * 0.05  # æ¯ä¸ªå­—ç¬¦è‡³å°‘50ms
                if word["end"] - word["start"] < min_word_duration:
                    word["end"] = word["start"] + min_word_duration
    
    logging.info("âœ” è½¬ç å®Œæˆ")
    return result

def format_timestamp(sec: float, vtt: bool=False) -> str:
    h, r = divmod(sec, 3600)
    m, s = divmod(r, 60)
    # ç¡®ä¿æ—¶é—´æˆ³ä¸ä¼šå‡ºç°è´Ÿå€¼
    h, m, s = max(0, h), max(0, m), max(0, s)
    if vtt:
        return f"{int(h):02d}:{int(m):02d}:{s:06.3f}"
    else:
        return f"{int(h):02d}:{int(m):02d}:{s:06.3f}".replace(".",",")

def split_text_into_lines(text: str, max_chars: int=42) -> List[str]:
    """æ™ºèƒ½åˆ†è¡Œ"""
    # é¦–å…ˆæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
    segments = re.split(r'([ã€‚ï¼ï¼Ÿ\?!])', text)
    lines = []
    current_line = []
    current_length = 0
    
    for segment in segments:
        if not segment:
            continue
        
        words = segment.split()
        for word in words:
            if current_length + len(word) + 1 > max_chars:
                if current_line:
                    lines.append(" ".join(current_line))
                current_line = [word]
                current_length = len(word)
            else:
                current_line.append(word)
                current_length += len(word) + 1
                
        # å¦‚æœæ˜¯æ ‡ç‚¹ç¬¦å·ï¼Œå¼ºåˆ¶æ¢è¡Œ
        if re.match(r'[ã€‚ï¼ï¼Ÿ\?!]', segment):
            if current_line:
                lines.append(" ".join(current_line))
            current_line = []
            current_length = 0
    
    if current_line:
        lines.append(" ".join(current_line))
    
    return lines

def write_subtitles(segments: List[Dict[str, Any]],
                    fmt: str,
                    out_path: str,
                    remove_fillers: bool = True) -> None:
    with open(out_path, "w", encoding="utf-8") as f:
        if fmt == "vtt":
            f.write("WEBVTT\n\n")
        
        idx = 1
        for seg in segments:
            words = seg.get("words", [])
            if not words:
                continue
                
            text = " ".join(w["word"] for w in words)
            if remove_fillers:
                text = re.sub(r"\b(um|uh|er|ah|oh)\b", "", text).strip()
            
            # åº”ç”¨æ–‡æœ¬åå¤„ç†
            text = post_process_text(text)
            
            lines = split_text_into_lines(text)
            
            for i in range(0, len(lines), 2):
                part = lines[i:i+2]
                start_idx = sum(len(x.split()) for x in lines[:i])
                end_idx   = sum(len(x.split()) for x in lines[:i+2])
                
                if start_idx >= len(words):
                    continue
                    
                t0 = words[start_idx]["start"]
                t1 = words[min(end_idx - 1, len(words) - 1)]["end"]
                
                # æ™ºèƒ½è°ƒæ•´æ—¶é•¿
                duration = t1 - t0
                min_dur = max(len(" ".join(part)) / 20, 1.8)  # ç•¥å¾®å¢åŠ æœ€å°æ˜¾ç¤ºæ—¶é—´
                max_dur = min(min_dur * 2.5, 7.0)  # è®¾ç½®æœ€å¤§æ˜¾ç¤ºæ—¶é—´
                
                if duration < min_dur:
                    t1 = t0 + min_dur
                elif duration > max_dur:
                    t1 = t0 + max_dur
                
                # ç¡®ä¿æ—¶é—´æˆ³é€’å¢
                if idx > 1:
                    prev_end = getattr(write_subtitles, 'prev_end', 0)
                    if t0 < prev_end:
                        t0 = prev_end + 0.001
                write_subtitles.prev_end = t1
                
                # è¿™é‡Œåªæœ‰ srt å’Œ vttï¼Œå®é™…åªä¼šè°ƒç”¨ srt
                if fmt == "srt":
                    f.write(f"{idx}\n")
                    f.write(f"{format_timestamp(t0)} --> {format_timestamp(t1)}\n")
                    f.write("\n".join(part) + "\n\n")
                else:  # vtt
                    f.write(f"{format_timestamp(t0, True)} --> {format_timestamp(t1, True)}\n")
                    f.write("\n".join(part) + "\n\n")
                idx += 1

# def write_transcript_txt(segments: List[Dict[str, Any]],
#                          out_path: str,
#                          remove_fillers: bool = True) -> None:
#     with open(out_path, "w", encoding="utf-8") as f:
#         for seg in segments:
#             txt = seg.get("text", "")
#             if remove_fillers:
#                 txt = re.sub(r"\b(um|uh|er|ah|oh)\b", "", txt).strip()
#             txt = post_process_text(txt)
#             f.write(txt + "\n")

def run_pipeline(video_path: str,
                 model_key: str = "large-v3",
                 language: str = None):
    try:
        logging.info(f"â–¶ å¤„ç†æ–‡ä»¶: {video_path}")
        model_repo = MODELS.get(model_key, model_key)
        
        # éŸ³é¢‘å¤„ç†
        audio = prepare_audio(video_path)
        result = process_audio(model_repo, audio, language)
        
        # åªè¾“å‡º .srt
        base     = OUTPUT_DIR / pathlib.Path(video_path).stem
        # vtt_path = f"{base}.vtt"
        srt_path = f"{base}.srt"
        # txt_path = f"{base}.txt"
        # json_path = f"{base}.json"
        # zip_path = f"{base}.zip"
        
        # ä¿å­˜åŸå§‹ç»“æœ
        # with open(json_path, 'w', encoding='utf-8') as f:
        #     json.dump(result, f, ensure_ascii=False, indent=2)
        
        # å†™å…¥å­—å¹•æ–‡ä»¶
        # write_subtitles(result["segments"], "vtt", vtt_path, remove_fillers=True)
        write_subtitles(result["segments"], "srt", srt_path, remove_fillers=True)
        # write_transcript_txt(result["segments"], txt_path, remove_fillers=True)
        
        # æ‰“åŒ…
        # with ZipFile(zip_path, "w") as z:
        #     for p in [vtt_path, srt_path, txt_path, json_path]:
        #         z.write(p, os.path.basename(p))
        
        logging.info(f"âœ” è½¬ç å®Œæˆï¼ŒSRT ä¿å­˜åœ¨: {srt_path}")
        # logging.info(f"   - {vtt_path}\n   - {srt_path}\n   - {txt_path}\n   - {json_path}\n   - {zip_path}")
        
    except Exception as e:
        logging.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        raise
    finally:
        # æ¸…ç† /tmp ä¸‹çš„å¢å¼ºéŸ³é¢‘æ–‡ä»¶
        for f in TEMP_DIR.glob("enhanced_*"):
            try:
                f.unlink()
            except:
                pass

def on_activate():
    root = tk.Tk()
    root.withdraw()
    path = filedialog.askopenfilename(
        title="Select a video file", 
        filetypes=[("video files","*.mp4 *.mov *.avi *.mkv")]
    )
    root.destroy()
    if path:
        chosen_model = "large-v3"
        chosen_lang  = None
        run_pipeline(path, chosen_model, chosen_lang)

if __name__ == "__main__":
    logging.info("ğŸ“º è¯·æŒ‰ âŒ˜+âŒ¥+C é€‰æ‹©è§†é¢‘å¹¶å¼€å§‹è½¬ç â€¦")
    on_activate()